# (Under Construction) Cloud Layer

This repository corresponds to the cloud layer and is used to deploy projects. This layer is responsible to deploy a specific project, using the [Cloud Input Vars](#cloud-input-vars) as the input values that contain the data needed to [deploy the project](#deploying-a-project).

_It's recommended to use a controller layer, like defined at http://github.com/lucasbasquerotto/ctl, to manage projects and generate those variables, instead of using this layer to deploy a project directly._

## Demo

Before start using this layer, it's easier to see it in action. Below is a simple demo used to deploy a project. The demo uses pre-defined [input variables](#cloud-input-vars), and then execute this layer to deploy a project.

To execute the demo you will need a container engine (like `docker` or `podman`).

1. Create an empty directory somewhere in your filesystem, let's say, `/var/demo`.

2. Create 2 directories in it: `env` and `data` (the names could be different, just remember to use these directories when mapping volumes to the container).

3. Create a `demo.yml` file inside `env` with the data needed to deploy the project:

```yaml
# Enter the data here (see the demo examples)
```

4. Deploy the project:

```shell
docker run -it --rm -v /var/demo/env:/env -v /var/demo/data:/lrd local/demo
```

**The above commands in a shell script:**

```shell
mkdir -p /var/demo/env /var/demo/data

cat <<'SHELL' > /var/demo/env/demo.yml
# Enter the data here (see the demo examples)
SHELL

docker run -it --rm -v /var/demo/env:/env -v /var/demo/data:/lrd local/demo
```

**That's it. The project was deployed.**

ðŸš€ You can see examples of project deployment demos [here](#).

The demos are great for what they are meant to be: demos, prototypes. **They shouldn't be used for development** (bad DX if you need real time changes without having to push and pull newer versions of repositories, furthermore you are unable to clone repositories in specific locations defined by you in the project folder). **They also shouldn't be used in production environments** due to bad security (the vault value used for decryption is `123456`, and changes to the [project environment repository](#project-environment) may be lost if you forget to push them).

# Deploying a Project

The deployment of a project in this layer is done, by default, in 3 steps.

1. [Cloud Preparation Step](#cloud-preparation-step)

2. [Cloud Context Preparation Step](#cloud-context-preparation-step)

3. [Cloud Context Main Step](#cloud-context-main-step)

## Project Base Directory

The project base directory is the directory (`project_base_dir`) in which the files generated by the project deployment and used to deploy the project are located. The `project_base_dir` should be in the path `<base_path>/projects/<project_name>/` where `<base_path>` is a base folder for the relative paths of repositories defined in `path_params` (used in development).

When running with the `dev` [input variable](#cloud-input-vars) equal `true`, there should be a relative symlink `<project_base_dir>/dev/link` that points to `<base_path>` to map repositories (so that you can share repositories across projects).

When running this step in a container, `<project_base_dir>/dev` should map to `<base_path>` in the host, and a symlink `<base_path>/link` should be created pointing to itself (`.`) so that the relative symlinks work both inside and outside the container.

_If using the controller layer at http://github.com/lucasbasquerotto/ctl to deploy the project, the project base directory will be at `<root_dir>/projects/<project_name>/` and the symlinks and volume mappings will be already handled._

## Cloud Input Vars

The [Cloud Preparation Step](#cloud-preparation-step) needs a file in the following format located at `<project_base_dir>/files/ctl/vars.yml` to deploy a project:

```yaml
ctxs:
- ctx1
- ctx2
dev: true
env_file: path/to/env.yml
env_params:
    param1: value1
    param2: value2
init:
    container: lucasbasquerotto/cloud:1.3.6
    container_type: docker
    root: true
    run_file: /usr/local/bin/run
key: project-key
migration: ''
path_params:
    path_env: repos/env
    path_env_base: repos/env-base
    path_map_repos:
        app: repos/app
        cloud: repos/cloud
        custom_cloud: repos/custom-cloud
        custom_pod: repos/custom-pod
        env_base: repos/env-base
        pod: repos/pod
project_dir_rel: projects/project-key
repo:
    src: ssh://git@github.com/lucasbasquerotto/project-env-demo.git
    ssh_file: ssh.key
    version: master
repo_vault:
    file: vault
    force: true
root_dir: <root_dir>
```

TODO explanation of the above

## Cloud Preparation Step

This step receives a `project-dir` parameter with the [project base directory](#project-base-directory), then use the [Cloud Input Vars](#cloud-input-vars) at `<project_base_dir>/files/ctl/vars.yml` to load the [Project Environment](#project-environment), and, finally, for each context defined in the input vars (`ctxs`), clone the cloud repository for that context.

This preparation step is commonly executted inside a container, runs only once for the project and is the same even if the cloud repositories for the contexts are different, so it's expected that all the contexts in a project are compatible with this preparation step, and any specific stuff related to the context is run in the [Cloud Context Preparation Step](#cloud-context-preparation-step).

When loading the environment variables defined in the [`env_file`](#project-environment-file), if `repo_vault.file` is defined, the vault file there is used to [decrypt the encrypted values](#encrypt-and-decrypt). The [`env_file`](#project-environment-file) can access use jinja2 expressions and has access to the following variables:

- `project_name` (`string`): the project name, the value of `key` in the [Cloud Input Vars](#cloud-input-vars).
- `project_ctxs` (`list` of `string`): the contexts that will run in the project, the value of `ctxs` in the [Cloud Input Vars](#cloud-input-vars). The value `ctxs` is optional in the [Cloud Input Vars](#cloud-input-vars), and if not defined there, should be defined in the `env_file` (or `env_base_file`)
- `params` (`dict`): any parameters defined at `env_params` in the [Cloud Input Vars](#cloud-input-vars).

Aside from `project-dir`, the file that [runs this preparation step](container/run.sh) also accepts the following options:

| Option        | Description |
| ------------- | ----------- |
| <nobr>`-f`</nobr><br><nobr>`--force`</nobr> | Force the execution even if the commit of the [project environment repository](#project-environment) is the same as the last time it was executed. |
| <nobr>`-n`</nobr><br><nobr>`--next`</nobr> | The deployment will use parameters passed after the project name to be used by the next steps. The parameters are specified at the [Cloud Next Parameters](#cloud-next-parameters) section._ |
| <nobr>`-p`</nobr><br><nobr>`--prepare`</nobr> | Only runs the [Cloud Preparation Step](#cloud-preparation-step) and [Cloud Context Preparation Step](#cloud-context-preparation-step).<br><br>This has a particular feature that allows to pass arguments to each step that will handle it (as long as subsequent layers handle it). For example, passing the args `-vv` would generally be used only by the last step ([Cloud Context Main Step](#cloud-context-main-step)), but in this case it will be used as args to run the [Cloud Preparation Step](#cloud-preparation-step) and no args to subsequent steps.<br><br>You can pass `--` to indicate the end of the arguments for a given step, so the following args `-a -b -c -- -d` will pass the argument `-a -b -c` to the [Cloud Preparation Step](#cloud-preparation-step), and `-d` to the [Cloud Context Preparation Step](#cloud-context-preparation-step). You can use `--skip` to skip a given step (you shouldn't pass `--` in this case). For example, `--skip -c -d` will skip the [Cloud Preparation Step](#cloud-preparation-step) and pass `-c -d` to the [Cloud Context Preparation Step](#cloud-context-preparation-step). |
| <nobr>`-s`</nobr><br><nobr>`--fast`</nobr> | Skips the [Cloud Preparation Step](#cloud-preparation-step) and [Cloud Context Preparation Step](#cloud-context-preparation-step). |
| <nobr>`--debug`</nobr> | Runs in verbose mode and forwards this option to the subsequent step. |

In this step, when the `dev` input var is `true`, the `path_params` value in the [Cloud Input Vars](#cloud-input-vars) file will be included in a new file at `<project_base_dir>/files/cloud/path-map.yml` so that the next steps can use it to map repositories to other locations and skip pulling already cloned repositories.

The value of `env_params` is written to the file `<project_base_dir>/files/cloud/env-params.yml` so that the next steps can use it to load the [`env_file`](#project-environment-file).

For each context in the project, 2 files with the same content in a different format will be created at `<project_base_dir>/files/cloud/ctxs/<ctx>/vars.yml` and `<project_base_dir>/files/cloud/ctxs/<ctx>/vars.sh` to be used in the [Cloud Context Preparation Step](#cloud-context-preparation-step) and [Cloud Context Main Step](#cloud-context-main-step). The contents of those files are defined in the [Cloud Context Input Vars](#cloud-context-input-vars) section.

This steps generate a file `<project_base_dir>/files/cloud/run-ctxs` to run each context passing as the first parameter the location of context directory (`<project_base_dir>/files/cloud/ctxs/<ctx>/`). Each context is run entirely ([Cloud Context Preparation Step](#cloud-context-preparation-step) and [Cloud Context Main Step](#cloud-context-main-step)) before starting the next context.

## Cloud Context Input Vars

These are the input variables used by the [Cloud Context Preparation Step](#cloud-context-preparation-step) and [Cloud Context Main Step](#cloud-context-main-step). They are generated by the [Cloud Preparation Step](#cloud-preparation-step). There are 2 files generated with the same content, but in a different format:

_`<project_base_dir>/files/cloud/ctxs/<ctx>/vars.sh`_

```shell
export repo_dir=''
export ctx_dev_dir=''
export vault_file=''
export secrets_cloud_dir=''
export dev_repos_dir=''
export ctx=''
export path_map_file=''
export repo_run_file=''
export project=''
export ctx_dir=''
export env_params_file=''
export env_dev=''
export env_dir=''
export env_file=''
export secrets_ctx_dir=''
```

_`<project_base_dir>/files/cloud/ctxs/<ctx>/vars.yml`_

```yaml
repo_dir: ''
ctx_dev_dir: ''
vault_file: ''
secrets_cloud_dir: ''
dev_repos_dir: ''
ctx: ''
path_map_file: ''
repo_run_file: ''
project: ''
ctx_dir: ''
env_params_file: ''
env_dev: ''
env_dir: ''
env_file: ''
secrets_ctx_dir: ''
```

TODO explanation of the above

## Cloud Context Preparation Step

This step as [defined in this repository](prepare.ctx.yml) does the following tasks:

1. Loads (from the environment repository) and validates the environment (`env`) variable schema (as defined in the corresponding [schema file](schemas/env.schema.yml)).

2. Prepare the repositories defined in the `extra_repos` defined for the context in the environment file (`main.<ctx>.extra_repos`), which could be used, for example, to setup all the required repositories of a development environment to setup the workspace. It also clones the repositories of the pods defined for the nodes of the context (used when transfering templates of the pod to the actual pod repository in remote hosts, because Ansible requires that templates should be in the local machine, as well as some validations). This step doen't run when the `--prepare` and `--fast` flags are specified.

3. Defines and validates the context (`ctx_data`) variable, [merging and overriding parameters](#mergeable-parameters), defining the context ansible fact to be used for the next steps, so that those steps don't need to do it again. Validates schemas for services, nodes, tasks and pods, and do several other types of validations, like the existence of some files that will be transfered.

4. Creates the hosts file to be used by Ansible when connecting to hosts (when new hosts are created dynamically, this file is updated) as well as the (optional) configuration file (`ansible.cfg`), that by default is the file [ansible/ansible.cfg](ansible/ansible.cfg), but can be overriden using the `cfg` property in the context object (in the environment file):

```yaml
# ...
main:
  my_context:
    repo: "cloud"
    cfg: |
      [defaults]
      interpreter_python=/usr/bin/python3
      stdout_callback = default
      collections_paths = collections
    hosts: |
      [main]
      localhost ansible_connection=local
      [host]
    # ...
  # ...
# ...
```

5. Creates the playbook to execute instructions in the hosts (from `files/run.tpl.yml` to `plays/run.yml`). This is needed because the instructions, and hosts to run the instructions, as well the order in which they are run, are dynamically defined in the project environment file, but Ansible expects that the playbook is already created and the hosts and plays to be statically defined when it starts to run the [Cloud Context Main Step](#cloud-context-main-step).

## Cloud Context Main Step

TODO

# Project Environment

The project environment is defined loading the [`env_file`](#project-environment-file) together with the params passed to it by the [Cloud Preparation Step](#cloud-preparation-step) (`project_name`, `project_ctxs` and `params`).

If the file has a top-level variable `env`, it will load the [`env_base_file`](#project-environment-base-file) passing the variables loaded from the [`env_file`](#project-environment-file) as params.

The loaded result from these files can be refered as being the **Project Environment**.

## Project Environment File

The project environment is defined loading the file defined in the variable `env_file` from the [Cloud Input Vars](#cloud-input-vars) together with the params passed to it by the [Cloud Preparation Step](#cloud-preparation-step) (`project_name`, `project_ctxs` and `params`).

This file should be inside the **project environment repository**, which should be cloned from `repo.src` with in the branch/tag `repo.version` specified in the [Cloud Input Vars](#cloud-input-vars). If `repo.ssh_file` is specified, the ssh file defined at `<project_base_dir>/secrets/ctl/` is used.

**Depending on the context, the project environment file may refer to the [Project Environment](#project-environment) itself.**

## Project Environment Base File

If the [`env_file`](#project-environment-file) has a top-level variable `env`, it will clone/pull the **project environment base repository** defined at `env.repo` in the directory `env.repo_dir` inside the project environment directory, then load the [`env_base_file`](#project-environment-base-file) defined at `env.file` relative to the project environment base repository, passing the variables loaded from the [`env_file`](#project-environment-file) as params.

It's not required for an [`env_file`](#project-environment-file) to have `env` specified in it to load variables from a base repository, but **this is very useful to share deployment variables between different environments (like staging and production)**, while keeping environment specific stuff, like endpoints, tokens, secrets, and other types of credentials in a separate directory.

_Example of an `env_file` that loads another file from a base repository:_

```yaml
name: "{{ project_name }}"
ctxs: "{{ project_ctxs }}"
env:
  repo:
    src: "https://github.com/lucasbasquerotto/project-env-base-demo.git"
    version: "master"
  repo_dir: "env-base"
  file: "common/repos.yml"
```

# Useful Information

## Cloud Next Parameters

The following are the parameters that can be specified when deploying a project, specific to this layer:

| Option | Description |
| ------ | ------- |
| <nobr>`--end`</nobr> | Will destroy what was created by the deployment, the nodes and services, as long as the property `can_destroy` is defined and is `true` for them. It sends the state `absent` and expects that the nodes and services know how to handle this state. This is almost the same as running without the `--next` parameter as one of the launch parameters, and passing `--tags=destroy`, except that using `--end` won't register the commit of the project environment repository (used to skip newer deployments with the same commit, when not using the `--force` option) for this deployment (which is the expected). |
| <nobr>`--ssh`</nobr> | Will ssh into the host specified by the context (`-c`/`--ctx`), node type (`-n`/`--node`) and index (`-i`/`--idx`), these params specified right after `--ssh`. When the context is not specified, if there is only one context in the deployment, this context will be used by default, otherwise an error will be thrown. When the node type is not specified, if there is only one node type in the context, this node type will be used by default, otherwise an error will be thrown. When the index is not specified, the default will be `1` (the first host with of the before mentioned node type). This ssh option can only be used after the preparation step is completed, and the hosts are defined in the hosts file (either directly or after a node service creates them). |

## Mergeable Parameters

The environment file accepts some sections with `params`, `group_params`, `shared_params` and `shared_group_params` that can be merged and overriden. **These mergeable parameters can be very useful to achieve a DRY approach, avoiding lots of duplication, but should be used moderately, so as to not generate an illegible environment file with lots of indirections.**

The values specified in `params` will be considered as is.

```yaml
services:
  my_service:
    params:
      param1: 1
      param2: 2
```

_The output is the same as the input._

The values specified in `group_params` must be a dictionary in which the value of each property is a string that references a property in a group params dictionary that contains the values that will be mapped to the initial dictionary properties. The group params dictionary depends on the context that the `group_params` is specified (for example, if defined in a service, the group params dictionary is `service_group_params` defined at the topmost layer of the project environment variable; if defined in a node, will be `node_group_params`; and so on).

```yaml
services:
  my_service:
    group_params:
      param1: "group_1"
      param2: "group_2"
service_group_params:
  group_1: 3
  group_2: 4
```

_Outputs:_

```yaml
services:
  my_service:
    params:
      param1: 3
      param2: 4
```

The values specified in `shared_params` must be an array of strings in which each string references a property in a shared params dictionary that contains the values that will be mapped to the whole parameter. The shared params dictionary depends on the context that the `shared_params` is specified (for example, if defined in a service, the shared params dictionary is `service_shared_params` defined at the topmost layer of the project environment variable; if defined in a node, will be `node_shared_params`; and so on).

The shared parameters are overriden in the order in which they are specified in the array, so the last one overrides all others, and the first is overriden by all others.

```yaml
services:
  my_service:
    shared_params: ["shared_1", "shared_2"]
shared_group_params:
  shared_1:
    param1: 11
    param2: 12
  shared_2:
    param2: 22
    param3: 23
```

_Outputs:_

```yaml
services:
  my_service:
    params:
      param1: 11
      param2: 22
      param3: 23
```

The values specified in `shared_group_params` must be a string that references a property in a shared group params dictionary that contains the values that will expanded as group parameters, and then mapped to the whole parameter as a shared parameter. The shared group params dictionary depends on the context that the `shared_group_params` is specified (for example, if defined in a service, the shared params dictionary is `service_shared_group_params` defined at the topmost layer of the project environment variable; if defined in a node, will be `node_shared_group_params`; and so on).

The properties in the shared group params dictionary should behavle as `group_params`, so they must be dictionaries in which each property value is a string that map to the group params dictionary.

```yaml
services:
  my_service:
    shared_group_params: "shared_group_1"
service_shared_group_params:
  shared_group_1:
    param1: "group_shared_1"
    param2: "group_shared_2"
service_group_params:
  group_shared_1: 123
  group_shared_2: 456
```

_Outputs:_

```yaml
services:
  my_service:
    params:
      param1: 123
      param2: 456
```

These sections are merged to result in a single parameter (`params`) property, with the precedence `shared_group_params` < `shared_params` < `group_params` < `params`, which means, for example, that what is defined in `params` will override the same parameter if specified in another section.

#TODO

## Contents

#TODO

## Custom Schemas

#TODO

# Encrypt and Decrypt

To encrypt and decrypt values and files, use `ansible-vault` as defined at http://github.com/lucasbasquerotto/ctl#encrypt-and-decrypt.
